{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5b601-f6f1-4786-ad24-990e8d9cc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/HAM/HAM10000_metadata')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcad59eb-56c1-49a2-9da9-b0391e8238c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['image_id', 'dx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a0818-601e-4e97-93fb-7bf6ebc8fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_id'] = df['image_id'] + '.jpg'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb9c70e4-30ea-44df-b6c9-7fd7ac351b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "folder_obrazow = 'data/HAM/HAM10000'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    nazwa_pliku = row['image_id']\n",
    "    klasa = row['dx']\n",
    "    sciezka_klasy = os.path.join(folder_obrazow, klasa)\n",
    "    if not os.path.exists(sciezka_klasy):\n",
    "        os.makedirs(sciezka_klasy)\n",
    "    zrodlo = os.path.join(folder_obrazow, nazwa_pliku)\n",
    "    cel = os.path.join(sciezka_klasy, nazwa_pliku)\n",
    "    shutil.move(zrodlo, cel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f90eddc5-5d5a-49db-aee7-e3e7370641d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_val_split(train_dir: str, val_dir: str) -> None:\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "    for folder_name in os.listdir(train_dir):\n",
    "        folder_path = os.path.join(train_dir, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            val_subfolder = os.path.join(val_dir, folder_name)\n",
    "            os.makedirs(val_subfolder, exist_ok=True)\n",
    "            files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if\n",
    "                     os.path.isfile(os.path.join(folder_path, f))]\n",
    "            train_files, validation_files = train_test_split(files, test_size=0.1, random_state=42)\n",
    "\n",
    "            for file in validation_files:\n",
    "                shutil.move(file, os.path.join(val_subfolder, os.path.basename(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ce00bba-4929-4e5e-8b4e-4b7bc84a4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/HAM/HAM10000'\n",
    "test_dir = 'data/HAM/HAM10000_test'\n",
    "train_val_split(train_dir, test_dir)\n",
    "val_dir = 'data/HAM/HAM10000_val'\n",
    "train_val_split(train_dir, val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd2dcf-08a1-4d90-9008-f3c4cba21b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_data = image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        color_mode='rgb',\n",
    "        image_size=(100, 75),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode='categorical',\n",
    "        )\n",
    "\n",
    "val_data = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    color_mode='rgb',\n",
    "    image_size=(100, 75),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    ")\n",
    "\n",
    "test_data = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(100, 75),\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "149e4685-f726-49ec-914b-10599f15d4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "import tensorflow as tf\n",
    "\n",
    "input_shape = (100, 75, 3)\n",
    "num_classes = 7\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  #  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    " #   tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "   # tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\")\n",
    "])\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9084a873-758f-4eb5-adb9-5d44dbdaa010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "49fe9bf0-6be9-417a-9540-0e3b6d151cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 22:52:44.198303: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_7/dropout_18/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 8s 56ms/step - loss: 8.7164 - accuracy: 0.6439 - val_loss: 1.0074 - val_accuracy: 0.6674 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.9813 - accuracy: 0.6708 - val_loss: 0.9585 - val_accuracy: 0.6707 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 8s 59ms/step - loss: 0.9402 - accuracy: 0.6684 - val_loss: 0.9144 - val_accuracy: 0.6762 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 8s 57ms/step - loss: 0.9233 - accuracy: 0.6696 - val_loss: 0.9204 - val_accuracy: 0.6829 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 8s 56ms/step - loss: 0.9126 - accuracy: 0.6728 - val_loss: 0.8565 - val_accuracy: 0.6939 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.9017 - accuracy: 0.6730 - val_loss: 0.8508 - val_accuracy: 0.6928 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 8s 59ms/step - loss: 0.8745 - accuracy: 0.6825 - val_loss: 0.8704 - val_accuracy: 0.6939 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 8s 57ms/step - loss: 0.8697 - accuracy: 0.6819 - val_loss: 0.8444 - val_accuracy: 0.6928 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.8424 - accuracy: 0.6943 - val_loss: 0.8484 - val_accuracy: 0.6961 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.8344 - accuracy: 0.6960 - val_loss: 0.8330 - val_accuracy: 0.6972 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 8s 56ms/step - loss: 0.8348 - accuracy: 0.6967 - val_loss: 0.8515 - val_accuracy: 0.6862 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 8s 57ms/step - loss: 0.8201 - accuracy: 0.7006 - val_loss: 0.8279 - val_accuracy: 0.7061 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 8s 58ms/step - loss: 0.7925 - accuracy: 0.7086 - val_loss: 0.8274 - val_accuracy: 0.7061 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 8s 56ms/step - loss: 0.8021 - accuracy: 0.7054 - val_loss: 0.8198 - val_accuracy: 0.7006 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 8s 56ms/step - loss: 0.7854 - accuracy: 0.7140 - val_loss: 0.8243 - val_accuracy: 0.7072 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "127/127 [==============================] - 8s 58ms/step - loss: 0.7528 - accuracy: 0.7187 - val_loss: 0.8159 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "127/127 [==============================] - 8s 58ms/step - loss: 0.7591 - accuracy: 0.7187 - val_loss: 0.8139 - val_accuracy: 0.7072 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "127/127 [==============================] - 8s 58ms/step - loss: 0.7484 - accuracy: 0.7194 - val_loss: 0.8374 - val_accuracy: 0.7072 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "127/127 [==============================] - 8s 57ms/step - loss: 0.7112 - accuracy: 0.7321 - val_loss: 0.8833 - val_accuracy: 0.6972 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "127/127 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.7372\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "127/127 [==============================] - 8s 57ms/step - loss: 0.7141 - accuracy: 0.7372 - val_loss: 0.8570 - val_accuracy: 0.7094 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=50, validation_data=val_data, callbacks=[earlystop, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63e70835-ea2b-4c22-be09-7fa00d9b3f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 45ms/step - loss: 0.7569 - accuracy: 0.7184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7569350600242615, 0.7184079885482788]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf8c0e-fd95-497e-98e7-ce70a6d4b4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
